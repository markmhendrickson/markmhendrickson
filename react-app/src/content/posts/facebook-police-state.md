Should Facebook really be responsible for [policing the misuse of user data](https://newsroom.fb.com/news/2018/03/forensic-audits-cambridge-analytica/) by companies that acquire it through legitimate means [then subsequently resell it to other entities](https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html), for whatever purpose?

Facebook is a broker that can directly control only how users and companies exchange data using its tools. Expecting the company to know – or even try to know – and respond to what happens to that data once data has been exchanged with its tools and taken off-platform is an impossible expectation for it to fulfill. We’re setting ourselves up as a society for continual disappointment and disillusionment having expected too much from a single organization.

Wouldn’t it be better to educate the general public about the risk of data reuse and resale should they opt to hand it over to whatever game or app developer through Facebook? Individuals could then decide if they want to assume that risk.

Facebook already gives individuals clear and granular controls on what to share. And journalism is currently raising awareness of what could possibly go wrong should people give away their data thoughtlessly. The mature response to these learnings isn’t to blame Facebook and delete your account; it’s to realize that Facebook has given you great power over your personal data and while many may have shared it unwisely, that doesn’t mean you have to as well.

Facebook and other monolithic networks aren’t social problems because they can’t control what goes on in or around them but rather because we expect and demand that they do.

We risk characterizing them as omnipotent parental figures that we should benevolently guide the multiplicity and complexity of our interactions while somehow resolving disputes with a fair hand.

But these aren’t governmental bodies and we’d be unwise to push them into that role by demanding they police data and behavior on their own or as agents of actual governments. They are international, capital-seeking enterprises, not representative bodies established, managed and adapted by referenda and all the protections of republican democracy. It’s hard enough to run a government responsive to the social needs of a specific population in an ever-globalized world. It’s madness to expect a company with nine board members and a user base of billions that spans the entire Earth to draw lines of social acceptability and benevolence let alone try to enforce them.

If we want paternalistically to prevent companies from exchanging personal data by applying categorical regulation, we already have real governments, locally, nationally and internationally available to do that. They can pass laws and enforce them, no matter how Facebook decides to expand or restrict its APIs and no matter how informed or ignorant its users are.

Want to prevent companies from reselling data without originator consent? Make it punishingly expensive to do so by weiding courts and class action lawsuits while taking care not to circumscribe the very concept of consent by infantilizing individuals and therefore assume consent itself is not pragmatically possible.

Did a company resell your data after promising it wouldn’t? Sue them. Did they never make that promise? Sorry, you’re out of luck. Just as you wouldn’t tell a secret to someone you don’t trust, you shouldn’t give any app access to your sensitive data if you don’t get legally enforceable guarantees to privacy.

The biggest shame that could come from our crisis of faith in Facebook and other platform providers would be to pressure the company into a defensive posture about the free flow of data and communication in general, effectively becoming totalitarian about its policies for fear of market and government retribution that stems from our impatient imposition of moral and legal responsibility.

Users will suffer from being treated as increasingly untrusted to share their data freely and whatever the form, whether demographic information, photos, status updates or medical history. Platforms will limit functionality to produce and exchange that data both on-platform and off, and the utility of their software will drop just as we expect it to rise in correspondence with our inflated sense of the pace of technology.

This will result in a two-pronged, contorted revolt against both the company’s tyranny and its impotence, leading eventually to mass emigration despite network lock-in effects. If this results in the use of decentralized platforms, people will have no choice but to seek social remedy from actual governments – that’d be the best-case scenario of creation arising from destruction.

If the migration leads to subsequent adoption of other centralized platforms, we risk entering into a cycle of losing progressively more liberty over our digital lives in the name of social safety and due to our lack of faith in higher authorities. The very platforms that are so uniquely situated to give us that positive liberty will be quixotically tasked with limiting it and that faith will only further degrade.